<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Model Iteration Series: Validating Model Research - Criss Wang&#039;s Log Book</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Criss Wang&#039;s Log Book"><meta name="msapplication-TileImage" content="https://cdn.statically.io/gh/Criss-Wang/image-host@master/Blog/Steins_Gate_Lab_Badge.webp"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Criss Wang&#039;s Log Book"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="The first line of defense to robust model iteration"><meta property="og:type" content="blog"><meta property="og:title" content="Model Iteration Series: Validating Model Research"><meta property="og:url" content="https://criss-wang.github.io/post/software/model-iteration-research-validation/"><meta property="og:site_name" content="Criss Wang&#039;s Log Book"><meta property="og:description" content="The first line of defense to robust model iteration"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://criss-wang.github.io/images/SWE/model_iteration_1.png"><meta property="article:published_time" content="2024-07-11T04:00:00.000Z"><meta property="article:modified_time" content="2024-07-28T05:51:39.030Z"><meta property="article:author" content="Zhenlin Wang"><meta property="article:tag" content="ML Infrastructure"><meta property="article:tag" content="Model Development"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://criss-wang.github.io/images/SWE/model_iteration_1.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://criss-wang.github.io/post/software/model-iteration-research-validation/"},"headline":"Model Iteration Series: Validating Model Research","image":["https://criss-wang.github.io/images/SWE/model_iteration_1.png"],"datePublished":"2024-07-11T04:00:00.000Z","dateModified":"2024-07-28T05:51:39.030Z","author":{"@type":"Person","name":"Zhenlin Wang"},"publisher":{"@type":"Organization","name":"Criss Wang's Log Book","logo":{"@type":"ImageObject","url":"https://cdn.statically.io/gh/Criss-Wang/image-host@master/Blog/Steins_Gate_Lab_Badge.webp"}},"description":"The first line of defense to robust model iteration"}</script><link rel="canonical" href="https://criss-wang.github.io/post/software/model-iteration-research-validation/"><link rel="icon" href="https://cdn.statically.io/gh/Criss-Wang/image-host@master/Blog/Steins_Gate_Lab_Badge.webp"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Roboto Slab:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }
          Array
              .from(document.querySelectorAll('.tab-content'))
              .forEach($tab => {
                  $tab.classList.add('is-hidden');
              });
          Array
              .from(document.querySelectorAll('.tabs li'))
              .forEach($tab => {
                  $tab.classList.remove('is-active');
              });
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="https://cdn.statically.io/gh/Criss-Wang/image-host@master/Blog/Steins_Gate_Lab_Badge.webp" alt="Criss Wang&#039;s Log Book" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" style="font-weight: bold" href="/">Criss&#039;s Time Machine</a><a class="navbar-item" style="font-weight: bold" href="/categories/Blogs">Machine Learning</a><a class="navbar-item" style="font-weight: bold" href="/categories/Software">Software Engineering</a><a class="navbar-item" style="font-weight: bold" href="/categories/Projects">Projects</a><a class="navbar-item" style="font-weight: bold" href="/research">Research</a><a class="navbar-item" style="font-weight: bold" href="/archives">Archives</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Criss-Wang/"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-4 is-size-5-mobile has-text-weight-normal">Model Iteration Series: Validating Model Research</h1><div class="article-meta is-size-7 level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-check">¬†</i><time dateTime="2024-07-11T04:00:00.000Z" title="2024-07-11T04:00:00.000Z">2024-07-11</time></span><span class="level-item"><i class="far fa-folder-open">¬†</i><a class="link-muted" href="/categories/Software/">Software</a></span></div></div><div><hr style="background-color:grey"></div><div style="padding-bottom:5px"></div><div class="content"><h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a><strong>Intro</strong></h2><p>As the first part of the model iteration, or any form of production-driven research projects that commonly take place in industry, we need to conduct data science or machine learning researches on the various components in a product pipeline. For this write-up, we are going to focus on the various steps and preparations needed for a proper LLM model-based research.</p>
<p>If you haven't read my blog that provides the high level insights to the series, I would urge you to kindly go through it to gain more context on this write-up. It is important to consider it as an integral part of the entire series, as I will mainly focus on a few parts of the model research. Specifically, I must emphasize that this blog is for LLM models. The considerations and design decisions required for other ML/AI models may be drastically different.</p>
<p>In the upcoming sections, I will discuss the following topics:</p>
<ul>
<li>Different forms of model investigations and how they become crucial to the iteration process</li>
<li>A proposed strategy to run LLM model investigation for Startup-like DS/ML/AI teams</li>
<li>How to run inference tests effectively</li>
<li>Some important points to take note of during LLM model research</li>
</ul>
<h2 id="Model-Investigation"><a href="#Model-Investigation" class="headerlink" title="Model Investigation"></a><strong>Model Investigation</strong></h2><figure align="center">
    <img src="/../../images/SWE/model_iteration_1.png" width="400px">
</figure>

<p>To reiterate from the intro blog, in a common model investigation process, we have 3 major types of model improvements that can be proposed:</p>
<ul>
<li>A better third party API</li>
<li>A better model architecture</li>
<li>A better set of model parameters ( customization, finetuning, etc‚Ä¶)</li>
</ul>
<p>Each type has its strength and weaknesses, as shown in the table below. They are interconnected to some extend, and some may be tested in parallel or in combination. However, all of them should eventually provide business value to the company directly or indirectly.</p>
<table>
<thead>
<tr>
<th></th>
<th>Time Span</th>
<th>Short-term Cost</th>
<th>Long-term Cost</th>
<th>Manpower</th>
<th>Performance Improvement</th>
<th>Suitable for</th>
</tr>
</thead>
<tbody><tr>
<td>Third Party API</td>
<td>Short</td>
<td>Low</td>
<td>High</td>
<td>Low</td>
<td>Low/Medium</td>
<td>Startups</td>
</tr>
<tr>
<td>Model Architecture-based</td>
<td>Long</td>
<td>High</td>
<td>Low/Medium</td>
<td>High</td>
<td>Depends</td>
<td>Big Tech</td>
</tr>
<tr>
<td>Model Parameter-based</td>
<td>Medium</td>
<td>Medium</td>
<td>Low</td>
<td>Medium</td>
<td>High</td>
<td>Startups &amp; Big Tech</td>
</tr>
</tbody></table>
<p>All ML/DS researchers that investigate these methods should be extremely cautious when proposing model changes to the existing ML system, as their investigations are the first line of defense when it comes to new ideas. Having experienced the tremendous effort of repeated validation process gone to drain simply because of flaws in research assumption has taught me the valuable lesson of double checking, even triple checking conjectures, changes, and impacts before presenting ideas for further testing. Therefore, I‚Äôve been developing robust validation systems like the <a target="_blank" rel="noopener" href="https://github.com/Criss-Wang/llm-benchmark/tree/main/configs/task_name"><strong>llm-validator</strong></a> myself inside and outside of work. I sincerely wish every team that‚Äôs responsible for LLM model investigation would be able to come up with some system like (and of course, better) this one to automate preliminary model validation during the research process.</p>
<h3 id="Proposed-Strategy-for-Model-Investigation"><a href="#Proposed-Strategy-for-Model-Investigation" class="headerlink" title="Proposed Strategy for Model Investigation"></a><strong>Proposed Strategy for Model Investigation</strong></h3><p>Every team that works on LLM has its own way of working towards better LLM models at different stages in the company development. In this section, I would like to propose a potentially valid and efficient method for teams that are in early stages (e.g. Startups, or newly formed LLM teams due to the AI frenzy). It's a 5-step process:</p>
<p><strong>Step 1: Pick a baseline model</strong></p>
<p>Most new teams don't have ready insights on a specific model to use for specific tasks they are given at the start. Thus any widely adopted universal model can be its starting point. The model can be some third party API providers like Bedrock, Anyscale or Together, or any direct model providers like OpenAI, Google or Anthropic. Avoid going into the trap of premature optimization in early stages. When things have not scaled up yet, the cost of using these large models far outweigh the cost of additional troubles caused by small open-source models or custom inference engines in the near future.</p>
<p>Ultimately, this model will become a <strong>baseline</strong> for new model changes proposed, and will remain as a reference point when models iterate. As our validation data changes, the statistics related to the baseline model should automatically change as a result.</p>
<p><strong>Step 2: Pick a configuration</strong></p>
<p>The model configurations here I want to suggest encompass the entire inference process. It includes the right set of parameters during API calling, like <code>temperature</code>, <code>max_tokens</code>, <code>top_p</code>, <code>is_streaming</code> or <code>function_calling</code>. It also includes the choice of providers. These design decisions are highly dependent on the tasks LLMs are trying to solve, and the side-effects that can be caused by them.</p>
<p><strong>Step 3: Consider the Projected Impact</strong></p>
<p>This step is often ignored by many junior scientists (including myself) who work on model iteration investigation. In order to make the change useful to the product/business, here are 5 important spectrums to consider:</p>
<ol>
<li><strong>Cost</strong>: amount of cost saving this change can bring</li>
<li><strong>Latency</strong>: reducing inference time or end-to-end process duration can boost customer satisfaction and secure more business eventually</li>
<li><strong>Accuracy</strong>: the performance boost is often the most obvious from science‚Äôs perspective, but often the less obvious in the product. Nonetheless, a significant leap in performance is usually the ultimate factor that enables a product to win.</li>
<li><strong>Security</strong>: Guardrail against attacks or harmful contents have been well studied in the last couple of years. It is the bottom-line of the product.</li>
<li><strong>Stability</strong>: it is the most ignored aspect among scientists, especially in LLM. Many researchers choose to ‚Äúintentionally‚Äù ignore stability as they attribute it to the inherent variations LLMs. However, bugs/issues will be reflected out of it, and they are easily sensed by the product users. Moreover, it is the hardest to identify.</li>
</ol>
<p>Think through each spectrum carefully ensures that we do not hurt other spectrums significantly when we focus on improving one or two aspects. This prevents a ton of issues from happening when we move into the later stages of model iteration.</p>
<p><strong>Step 4: Observe, Execute, and Analyze</strong></p>
<p>I have always had trust in my fellow colleagues for their resourcefulness while searching for model changes. They know how to find the right set of tools to run experiments, make tweaks, and analyze results to further ensure the required model changes are formed and validated. This step is by far the hardest (because it involves lots of execution and thinking), and yet the most trusted part.</p>
<p>In order to offer some additional guidance to people who are still new to model validation, I have included in the bottom section a demo using my <a target="_blank" rel="noopener" href="https://github.com/Criss-Wang/llm-benchmark/tree/main/configs/task_name"><strong>llm-validator</strong></a> repo on how to run a validation process when we change from GPT-4 to Claude 3.5 Sonnet. The same steps can be reproduced across many model changes, and can be done in a systematic way.</p>
<p><strong>Step 5: Compile and Ship</strong></p>
<p>Provide the proposed model changes and the updated model metadata to ML Infra engineers will be the final step of this model investigation process. Ensure proper documentation, fallback plans and justification are ready in place. It will then go for a more intricate latency test and cost analysis thereafter.</p>
<h2 id="More-on-Accuracy-and-Stability"><a href="#More-on-Accuracy-and-Stability" class="headerlink" title="More on Accuracy and Stability"></a><strong>More on Accuracy and Stability</strong></h2><p>At the model investigation stage, even though we have to consider all 5 spectrums of the <strong>CLASS</strong> objective, we won't necessarily have the resources, scope and expertise to fully evaluate <em>cost</em>, <em>latency</em> and <em>security</em>. Hence researchers are most likely gonna focus on <em>accuracy</em> and <em>stability</em>. Here, I will share my two cents on an ideal workflow to conduct these tests <strong>after</strong> we formulate and implement the changes in code.</p>
<p><strong>A/B Testing is the basic</strong></p>
<p>It is almost a second nature for DS/MLE to conduct A/B testing when they are given a proposed solution and a baseline solution. The same should be said for accuracy and stability tests. The usual way of A/B testing still holds. If you're still unfamiliar with it, I urge you to follow some tutorials to understand the steps to run it. You can ready any materials online, or just take a shortcut and read <a target="_blank" rel="noopener" href="https://criss-wang.com/post/blogs/mlops/AB-testing/">my post here</a>.</p>
<p><strong>Components of the inference</strong></p>
<p>We use A/B testing as the backbone of these tests, and now it is time to fill up the content:</p>
<ul>
<li><strong>Task</strong>: what is the input/output format? what is the expected outcome &amp; format? why is it critical to test model changes on this task?</li>
<li><strong>Dataset</strong>: where is the raw input sourced from? how is it labeled (human vs LLM)? what‚Äôs the size? is there potential data quality issues?</li>
<li><strong>Model/Engine</strong>: what are the basic config parameters? is it supposed to be time-consuming? what is the cost of model inference for each complete test? are there error handling mechanisms that ensure the tests run smoothly?</li>
<li><strong>Prompt</strong>: what is the prompt being used? are we using the same one the baseline model is using? what version and what variables? do we have a metaprompt for it?</li>
<li><strong>Metrics</strong>: what are the set of scores we need to measure? is it naturally varying a lot? is there any obsolete metric we need to replace with new ones?</li>
</ul>
<p>When it comes to accuracy, we must ensure the testing data is large enough to cover the input domain well, and the metric is reflective of the goal. For example, if we are to run chunk validation using LLM, then we should consider aspects like chunk relevancy, chunk precision/recall, and ensure the knowledge base is well represented by the chunks in datasets. The results against baseline should also be statistically significant for the proposed solution to hold.</p>
<p>When it comes to stability, there should be datasets with very similar queries. We have the expectation of identical, or if not, very similar outputs from the model using these similar queries, similarity scores should be measured, and deviations should be further analyzed and further model tuning may be requested upon issues identified.</p>
<p><strong>Logging</strong></p>
<p>Run the tests and generate statistics for it. A good validator should be able to return the results in forms of distributions, output datasets and metric scores. In the meantime, it should log any warnings and errors that may alert the researchers the hidden danger of applying this change to production systems.</p>
<h2 id="A-simple-demo-of-validation-GPT-gt-Claude-migration"><a href="#A-simple-demo-of-validation-GPT-gt-Claude-migration" class="headerlink" title="A simple demo of validation GPT -> Claude migration"></a><strong>A simple demo of validation GPT -&gt; Claude migration</strong></h2><p>For the rest of the blog mostly contains a demo to show how the validation part is achieved via a systematic pipeline. In this demo, we set up a story that some DS found out <code>Claude-3.5-sonnet</code> performs much better than <code>GPT-4</code> and decides to propose that migration for a code generation service. Our role is to validate such proposal from the accuracy perspective using an <a target="_blank" rel="noopener" href="https://github.com/Criss-Wang/llm-benchmark/tree/main/configs/task_name"><strong>llm-validator</strong></a>.</p>
<h3 id="Step-1"><a href="#Step-1" class="headerlink" title="Step 1"></a>Step 1</h3><p>As a first step, clone the repo <a target="_blank" rel="noopener" href="https://github.com/Criss-Wang/llm-benchmark/tree/main/configs/task_name">[Link]</a>, and specify the major components:</p>
<p><strong>Task</strong>: Code generation</p>
<ul>
<li>Input: user query with code snippet</li>
<li>Output: completed code section</li>
<li>Expectation: Code is complete and correct</li>
</ul>
<p><strong>Dataset</strong>: a simple demo dataset can be found in the repo: <a target="_blank" rel="noopener" href="https://github.com/Criss-Wang/llm-validator/blob/main/datasets/code_generation/test.csv"><em>Link</em></a></p>
<ul>
<li>Note: to achieve A/B testing, you should curate sufficient data <em>with multiple batches</em> to make it statistically significant.</li>
</ul>
<p><strong>Model</strong>: We have two models to investigate, so we use <code>AnthropicClient</code> and <code>OpenAiClient</code></p>
<ul>
<li><p>Note: if you need to use a custom client, please refer to the implementations <a target="_blank" rel="noopener" href="https://github.com/Criss-Wang/llm-validator/blob/main/llm_validation/components/clients/anthropic.py">here</a> as a guideline.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Dict</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> anthropic</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> llm_validation.components.clients <span class="keyword">import</span> Client</span><br><span class="line"><span class="keyword">from</span> llm_validation.app.configs <span class="keyword">import</span> ClientConfig</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AnthropicClient</span>(<span class="title class_ inherited__">Client</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, config: ClientConfig</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(config)</span><br><span class="line">        self.api_key = os.getenv(<span class="string">"ANTHROPIC_API_KEY"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">predict_stream</span>(<span class="params">self, messages: <span class="type">List</span></span>):</span><br><span class="line">        client = anthropic.Anthropic(api_key=self.api_key)</span><br><span class="line">        stream = client.messages.create(</span><br><span class="line">            model=self.model_name,</span><br><span class="line">            system=messages[<span class="number">0</span>][<span class="string">"content"</span>],</span><br><span class="line">            messages=messages[<span class="number">1</span>:],</span><br><span class="line">            stream=<span class="literal">True</span>,</span><br><span class="line">            **self.model_options,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> chunk <span class="keyword">in</span> stream:</span><br><span class="line">            <span class="keyword">if</span> chunk.<span class="built_in">type</span> == <span class="string">"message_start"</span>:</span><br><span class="line">                self.input_tokens = chunk.message.usage.input_tokens</span><br><span class="line">            <span class="keyword">elif</span> chunk.<span class="built_in">type</span> == <span class="string">"content_block_delta"</span>:</span><br><span class="line">                <span class="keyword">yield</span> <span class="built_in">dict</span>(</span><br><span class="line">                    text=chunk.delta.text,</span><br><span class="line">                    raw_response=chunk,</span><br><span class="line">                )</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, messages: <span class="type">List</span></span>) -&gt; <span class="type">Dict</span>:</span><br><span class="line">        client = anthropic.Anthropic(api_key=self.api_key)</span><br><span class="line">        response = client.messages.create(</span><br><span class="line">            model=self.model_name,</span><br><span class="line">            system=messages[<span class="number">0</span>][<span class="string">"content"</span>],</span><br><span class="line">            messages=messages[<span class="number">1</span>:],</span><br><span class="line">            **self.model_options,</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">dict</span>(</span><br><span class="line">            text=response.content[<span class="number">0</span>].text,</span><br><span class="line">            raw_response=response,</span><br><span class="line">            usage=<span class="built_in">dict</span>(response.usage),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">extract_usage</span>(<span class="params">self, <span class="built_in">type</span>: <span class="built_in">str</span> = <span class="string">"input"</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span> == <span class="string">"input"</span> <span class="keyword">and</span> self.input_tokens:</span><br><span class="line">            <span class="keyword">return</span> self.input_tokens</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>Prompt</strong>: stored in <code>yaml</code> format</p>
<ul>
<li>task prompt: <a target="_blank" rel="noopener" href="https://github.com/Criss-Wang/llm-validator/blob/main/prompts/code_generation.yaml"><code>code_generation.yaml</code></a></li>
<li>judge prompt: <a target="_blank" rel="noopener" href="https://github.com/Criss-Wang/llm-validator/blob/main/prompts/judge.yaml"><code>judge.yaml</code></a></li>
</ul>
<p><strong>Metrics</strong>: We need to use llm-as-a-judge for this performance evaluation. It is readily defined in the repo as. <code>CodeGenAccuracy</code> under <code>components.metrics.accuracy</code> file, feel free to edit it to fit your needs.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CodeGenAccuracy</span>(<span class="title class_ inherited__">AccuracyMetric</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, config: MetricConfig</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(config)</span><br><span class="line">        client_config = ClientConfig(</span><br><span class="line">            name=<span class="string">"openai"</span>,</span><br><span class="line">            <span class="built_in">type</span>=<span class="string">"research"</span>,</span><br><span class="line">            model_name=<span class="string">"gpt-4o-mini"</span>,</span><br><span class="line">            base_url=<span class="string">""</span>,</span><br><span class="line">            model_options={<span class="string">"temperature"</span>: <span class="number">0</span>, <span class="string">"top_p"</span>: <span class="number">1</span>, <span class="string">"max_tokens"</span>: <span class="number">1024</span>},</span><br><span class="line">        )</span><br><span class="line">        prompt_config = PromptConfig(</span><br><span class="line">            name=<span class="string">"code-generation-judge"</span>,</span><br><span class="line">            path=<span class="string">"prompts/judge.yaml"</span>,</span><br><span class="line">            version=<span class="number">1</span>,</span><br><span class="line">        )</span><br><span class="line">        self.client = OpenAiClient(client_config)</span><br><span class="line">        self.prompt = Prompt(prompt_config)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">grade</span>(<span class="params">self, <span class="built_in">input</span>, output: <span class="built_in">str</span>, label: <span class="built_in">str</span></span>):</span><br><span class="line">        messages = self.prompt.transform(</span><br><span class="line">            generated_code_answer=output, expected_code_answer=label</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            result_content = self.client.sync_predict(messages)</span><br><span class="line">            result_content = json.loads(result_content[<span class="string">"text"</span>])</span><br><span class="line">            reason = result_content[<span class="string">"reason"</span>]</span><br><span class="line">            code_quality = result_content[<span class="string">"code_quality"</span>]</span><br><span class="line">            response_quality = result_content[<span class="string">"response_quality"</span>]</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(e)</span><br><span class="line">            reason = <span class="string">"error"</span></span><br><span class="line">            code_quality = <span class="string">"wrong"</span></span><br><span class="line">            response_quality = <span class="string">"bad"</span></span><br><span class="line">        <span class="keyword">return</span> {</span><br><span class="line">            <span class="string">"reason"</span>: reason,</span><br><span class="line">            <span class="string">"code_quality"</span>: code_quality,</span><br><span class="line">            <span class="string">"response_quality"</span>: response_quality,</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">aggregate</span>(<span class="params">self</span>):</span><br><span class="line">        code_quality = self.scores[<span class="string">"code_quality"</span>]</span><br><span class="line">        response_quality = self.scores[<span class="string">"response_quality"</span>]</span><br><span class="line">        self.stats.update(<span class="built_in">dict</span>(Counter(code_quality)))</span><br><span class="line">        self.stats.update(<span class="built_in">dict</span>(Counter(response_quality)))</span><br></pre></td></tr></table></figure>

<ul>
<li>Note: similar to customizable <code>client</code>, my code enables great flexibility for you to define additional metrics, just refer to the <a target="_blank" rel="noopener" href="https://github.com/Criss-Wang/llm-validator/blob/main/llm_validation/components/metrics"><code>metric</code></a> folder to find things you need.</li>
</ul>
<h3 id="Step-2-Define-the-configuration"><a href="#Step-2-Define-the-configuration" class="headerlink" title="Step 2: Define the configuration"></a>Step 2: Define the configuration</h3><p>The configuration file should be stored under <code>configs/{your_taks_name}</code> folder. In this demo, it is <code>configs/code_generation/openai.json</code> and <code>configs/code_generation/anthropic.json</code>. The config follows the format as shown below:</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">{</span></span><br><span class="line">  <span class="attr">"project"</span><span class="punctuation">:</span> <span class="string">"llm-validation"</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"task_config"</span><span class="punctuation">:</span> <span class="punctuation">{</span></span><br><span class="line">    <span class="attr">"name"</span><span class="punctuation">:</span> <span class="string">"code-generation"</span></span><br><span class="line">  <span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"client_config"</span><span class="punctuation">:</span> <span class="punctuation">{</span></span><br><span class="line">    <span class="attr">"name"</span><span class="punctuation">:</span> <span class="string">"openai"</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">"type"</span><span class="punctuation">:</span> <span class="string">"research"</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">"model_name"</span><span class="punctuation">:</span> <span class="string">"gpt-4o-mini"</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">"model_options"</span><span class="punctuation">:</span> <span class="punctuation">{</span></span><br><span class="line">      <span class="attr">"temperature"</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"max_tokens"</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"top_p"</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">    <span class="punctuation">}</span></span><br><span class="line">  <span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"prompt_config"</span><span class="punctuation">:</span> <span class="punctuation">{</span></span><br><span class="line">    <span class="attr">"name"</span><span class="punctuation">:</span> <span class="string">"code-generation-prompt-v1"</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">"path"</span><span class="punctuation">:</span> <span class="string">"prompts/code_generation.yaml"</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">"version"</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">  <span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"evaluator_config"</span><span class="punctuation">:</span> <span class="punctuation">{</span></span><br><span class="line">    <span class="attr">"metrics"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">{</span></span><br><span class="line">        <span class="attr">"type"</span><span class="punctuation">:</span> <span class="string">"accuracy"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"aspect"</span><span class="punctuation">:</span> <span class="string">"codegen"</span></span><br><span class="line">      <span class="punctuation">}</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"dataset_config"</span><span class="punctuation">:</span> <span class="punctuation">{</span></span><br><span class="line">    <span class="attr">"data_path"</span><span class="punctuation">:</span> <span class="string">"datasets/code_generation/test.csv"</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">"label_col"</span><span class="punctuation">:</span> <span class="string">"true_label"</span></span><br><span class="line">  <span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"controller_config"</span><span class="punctuation">:</span> <span class="punctuation">{</span></span><br><span class="line">    <span class="attr">"save_path"</span><span class="punctuation">:</span> <span class="string">"results"</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">"parallelism"</span><span class="punctuation">:</span> <span class="number">12</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">"use_streaming"</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">  <span class="punctuation">}</span></span><br><span class="line"><span class="punctuation">}</span></span><br></pre></td></tr></table></figure>

<p>In this demo, I‚Äôve already provided the completed configuration for you. If you would like to customize the config, refer to the <a target="_blank" rel="noopener" href="https://github.com/Criss-Wang/llm-validator/blob/main/llm_validation/app/configs.py"><code>configs.py</code></a> to understand the additional set of parameters.</p>
<h3 id="Step-3-Run-experiment"><a href="#Step-3-Run-experiment" class="headerlink" title="Step 3: Run experiment"></a>Step 3: Run experiment</h3><p>Run <code>pip install -e .</code> and <code>pip install -r requirements.dev.txt</code> to set the project up. Notice that you may need to have a Weights &amp; Biases account for experiment logging. After that, we are ready to kick-off the experiment by running the following command:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">llm-validator run --config-path=configs/code_generation/openai.json</span><br></pre></td></tr></table></figure>

<p>You will be able to see the results both from console and from W&amp;B dashboard. A sample outcome would look like the following</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Calling LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03&lt;00:00,  1.56s/it]</span><br><span class="line">-------- Accuracy ----------</span><br><span class="line">incomplete: 2</span><br><span class="line">fair: 2</span><br><span class="line">wandb: - 0.006 MB of 0.006 MB uploaded</span><br><span class="line">wandb: Run history:</span><br><span class="line">wandb:       Accuracy_fair ‚ñÅ</span><br><span class="line">wandb: Accuracy_incomplete ‚ñÅ</span><br><span class="line">wandb:</span><br><span class="line">wandb: Run summary:</span><br><span class="line">wandb:       Accuracy_fair 2</span><br><span class="line">wandb: Accuracy_incomplete 2</span><br><span class="line">wandb:</span><br><span class="line">wandb: üöÄ View run gpt-4o-mini-20240720-123403 at: https://wandb.ai/criss_w/llm-validation/runs/7rzhrlt4</span><br><span class="line">wandb: ‚≠êÔ∏è View project at: https://wandb.ai/criss_w/llm-validation</span><br><span class="line">wandb: Synced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)</span><br><span class="line">wandb: Find logs at:</span><br></pre></td></tr></table></figure>

<h3 id="Step-4-Repeat-for-both-models"><a href="#Step-4-Repeat-for-both-models" class="headerlink" title="Step 4: Repeat for both models"></a>Step 4: Repeat for both models</h3><p>Remember to run multiple epochs on different datasets, aggregate and analyze.</p>
<p>And <strong>hooray</strong>!!! We have completed a first attempt at validating the migration proposal.</p>
<h3 id="A-take-home-challenge"><a href="#A-take-home-challenge" class="headerlink" title="A take-home challenge"></a>A take-home challenge</h3><p>Notice that I described the metric implementation for accuracy, but not stability. Investigating stability is a completely different challenge, and I urge you to try implementing the metric logic yourself. If you have any question, raise a issue in the repo, and I'll clarify it for you with respect to this interesting challenge.</p>
<h2 id="Final-words"><a href="#Final-words" class="headerlink" title="Final words"></a><strong>Final words</strong></h2><p>Once again, the endeavor to further improve the model iteration process does not stop here. We have a lot more to go through from the model serving perspective, and it will become much more tricky from there onwards. Nonetheless, that's where a whole new world unfolds in front of us, especially those new grads who mostly deal with static and performance-oriented services building. Before that blog comes out, <strong><em>Stay Hunger, Stay Foolish</em></strong>.</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Model Iteration Series: Validating Model Research</p><p><a href="https://criss-wang.github.io/post/software/model-iteration-research-validation/">https://criss-wang.github.io/post/software/model-iteration-research-validation/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Zhenlin Wang</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2024-07-11</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2024-07-28</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"></article></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/post/software/model-iteration-infra/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Model Iteration Series: Validating Model Infra</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/post/software/model-iteration-intro/"><span class="level-item">Model Iteration Series: Intro</span><i class="level-item fas fa-chevron-right"></i></a></div></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://cdn.statically.io/gh/Criss-Wang/image-host@master/Blog/Selfie.webp" alt="Zhenlin Wang (Criss)"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Zhenlin Wang (Criss)</p><div class="is-size-7 multiline is-block justify-content-center" style="white-space:pre;font-style: italic">Software Development
Machine Learning
Artificial Intelligence
</div><div style="padding-top: 10px;"></div><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Sunnyvale, CA</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">72</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">38</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">46</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Criss-Wang/" target="_blank" rel="noopener"><i class="fab fa-github"></i>¬†¬† Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Criss-Wang/"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="LinkedIn" href="https://www.linkedin.com/in/zhenlin-wang/"><i class="fab fa-linkedin-in"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:zhenlinw@cs.cmu.edu"><i class="fas fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="CV" href="https://twitter.com/CrissWang4"><i class="fab fa-twitter"></i></a></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Deep-Learning/"><span class="tag">Deep Learning</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-Mining-Data-Engineering/"><span class="tag">Data Mining/Data Engineering</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unsupervised-Learning/"><span class="tag">Unsupervised Learning</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Optimization/"><span class="tag">Optimization</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reinforcement-Learning/"><span class="tag">Reinforcement Learning</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Supervised-Learning/"><span class="tag">Supervised Learning</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Clustering/"><span class="tag">Clustering</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Database-System/"><span class="tag">Database System</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ML-Infrastructure/"><span class="tag">ML Infrastructure</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Model-Development/"><span class="tag">Model Development</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Big-Data/"><span class="tag">Big Data</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Statistics/"><span class="tag">Statistics</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/System-Design/"><span class="tag">System Design</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Recommender-Systems/"><span class="tag">Recommender Systems</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQL/"><span class="tag">SQL</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regression/"><span class="tag">Regression</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Software-Engineering/"><span class="tag">Software Engineering</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-Analytics/"><span class="tag">Data Analytics</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Distributed-Training/"><span class="tag">Distributed Training</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Boosting/"><span class="tag">Boosting</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python-Project/"><span class="tag">Python Project</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Distributed-System/"><span class="tag">Distributed System</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cloud-Computing/"><span class="tag">Cloud Computing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/A-B-testing/"><span class="tag">A/B testing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLM/"><span class="tag">LLM</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Matrix-Computation/"><span class="tag">Matrix Computation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dimensionality-Reduction/"><span class="tag">Dimensionality Reduction</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Distributed-Systems/"><span class="tag">Distributed Systems</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Evaluation/"><span class="tag">Evaluation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MLOps/"><span class="tag">MLOps</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Project-Management/"><span class="tag">Project Management</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hidden-Markov-Models/"><span class="tag">Hidden Markov Models</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dynamic-Programming/"><span class="tag">Dynamic Programming</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Statistical-Inference/"><span class="tag">Statistical Inference</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Representaiton-Learning/"><span class="tag">Representaiton Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bayesian-Statistics/"><span class="tag">Bayesian Statistics</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Deep-learning/"><span class="tag">Deep learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linear-Algebra/"><span class="tag">Linear Algebra</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Control-Theory/"><span class="tag">Control Theory</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ensemble/"><span class="tag">Ensemble</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bagging/"><span class="tag">Bagging</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Random-Forest/"><span class="tag">Random Forest</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regularization/"><span class="tag">Regularization</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Classification/"><span class="tag">Classification</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Evaluation-Methods/"><span class="tag">Evaluation Methods</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Intro"><span class="level-left"><span class="level-item">1</span><span class="level-item">Intro</span></span></a></li><li><a class="level is-mobile" href="#Model-Investigation"><span class="level-left"><span class="level-item">2</span><span class="level-item">Model Investigation</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Proposed-Strategy-for-Model-Investigation"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">Proposed Strategy for Model Investigation</span></span></a></li></ul></li><li><a class="level is-mobile" href="#More-on-Accuracy-and-Stability"><span class="level-left"><span class="level-item">3</span><span class="level-item">More on Accuracy and Stability</span></span></a></li><li><a class="level is-mobile" href="#A-simple-demo-of-validation-GPT-gt-Claude-migration"><span class="level-left"><span class="level-item">4</span><span class="level-item">A simple demo of validation GPT -&gt; Claude migration</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Step-1"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">Step 1</span></span></a></li><li><a class="level is-mobile" href="#Step-2-Define-the-configuration"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">Step 2: Define the configuration</span></span></a></li><li><a class="level is-mobile" href="#Step-3-Run-experiment"><span class="level-left"><span class="level-item">4.3</span><span class="level-item">Step 3: Run experiment</span></span></a></li><li><a class="level is-mobile" href="#Step-4-Repeat-for-both-models"><span class="level-left"><span class="level-item">4.4</span><span class="level-item">Step 4: Repeat for both models</span></span></a></li><li><a class="level is-mobile" href="#A-take-home-challenge"><span class="level-left"><span class="level-item">4.5</span><span class="level-item">A take-home challenge</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Final-words"><span class="level-left"><span class="level-item">5</span><span class="level-item">Final words</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="https://cdn.statically.io/gh/Criss-Wang/image-host@master/Blog/Steins_Gate_Lab_Badge.webp" alt="Criss Wang&#039;s Log Book" height="28"></a><p class="is-size-7"><span>&copy; 2024 Zhenlin Wang</span>¬†¬†Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>¬†&amp;¬†<a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="/js/night.js" defer></script><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">√ó</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>